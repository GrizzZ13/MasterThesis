% !TEX root = ../main.tex

\chapter{总结与展望}

\section{工作总结}

本文面向大模型分布式推理对高带宽、低时延与低计算干扰通信能力的迫切需求，
围绕“控制面卸载（Control Plane Offloading）”这一核心思想，提出并实现了通信库 \sysname。
针对现有 GPU 通信方案在推理场景下普遍存在的控制面与计算争用、复杂流量下调度能力不足等问题，
\sysname 将通信控制逻辑从 GPU SM 中解耦出来，交由 CPU 侧后台线程在统一运行时框架下持续推进，
并结合优先级与分片机制实现对延迟敏感请求更友好的调度行为。

在系统设计上，\sysname 通过统一的 \texttt{send()} / \texttt{recv()} 双向接口抽象屏蔽底层链路差异，
在跨节点场景使用 GPUDirect RDMA 构建高效的数据面通路，在节点内场景则基于 CUDA IPC 与 Copy Engine 实现 SM-free 的高带宽搬运。
在实现层面，本文给出了事件机制、运行时轮询框架以及 RDMA/NVLink 两类链路执行器的关键工程细节与性能优化，
包括控制面批处理、GPUDirect RDMA 可见性保证以及 CUDA IPC 映射缓存复用等。

实验结果表明，相比 NCCL 等基线方案，\sysname 在点对点与集合通信场景下能够提供具有竞争力的带宽表现，
并显著降低通信对前台计算的干扰；在端到端推理负载中，\sysname 能够保持更稳定的解码节奏，
验证了控制面卸载与优先级调度在真实推理系统中的有效性。

\section{未来展望}

尽管本文已验证 \sysname 在典型推理通信路径上的性能优势，但仍有若干值得进一步探索的方向：

\begin{itemize}
      \item \textbf{更丰富的通信原语与拓扑适配。} 将 \sysname 扩展到更多集合通信算子与更复杂的拓扑结构，
            并在保持统一抽象的同时进一步提升多机多卡大规模场景下的可扩展性。
      \item \textbf{自适应轮询与资源开销控制。} 结合负载特征与系统状态，动态调整轮询频率、在途量与线程亲和性配置，
            在低负载时降低 CPU 占用，在高负载时保持低时延与高吞吐。
      \item \textbf{与推理系统调度的深度协同。} 将通信优先级与推理框架的请求级调度策略打通，
            在 PD 分离、在线扩缩容与多租户场景下实现端到端的 QoS 保障与尾延迟优化。
\end{itemize}

上述工作有望进一步提升 \sysname 在更广泛推理系统场景中的适用性与工程价值。
